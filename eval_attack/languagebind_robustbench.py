import torch
import pandas as pd
import numpy as np
import os
from collections import defaultdict
from more_itertools import chunked
from tqdm.auto import tqdm
from autoattack import AutoAttack
from languagebind import LanguageBind, to_device, transform_dict, LanguageBindImageTokenizer
import json
import random

# ========== é…ç½® ==========
device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
clip_type = {
    'video': 'LanguageBind_Video_FT',  # ä½¿ç”¨FTç‰ˆæœ¬
}

# æ•°æ®é›†è·¯å¾„
csv_file = '/root/autodl-tmp/LanguageBind/datasets/datasets--friedrichor--MSR-VTT/snapshots/c1af215a96934854f42683c19c51391aaee6f962/raw_data/MSRVTT_JSFUSION_test.csv'
video_base_path = '../data/MSRVTT/videos/all'

import torch
import pandas as pd
import numpy as np
import os
from collections import defaultdict
from more_itertools import chunked
from tqdm.auto import tqdm
from autoattack import AutoAttack
from languagebind import LanguageBind, to_device, transform_dict, LanguageBindImageTokenizer
import json
import random

# ========== é…ç½® ==========
device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
clip_type = {
    'video': 'LanguageBind_Video_FT',  # ä½¿ç”¨FTç‰ˆæœ¬
}

# æ•°æ®é›†è·¯å¾„
csv_file = '/root/autodl-tmp/LanguageBind/datasets/datasets--friedrichor--MSR-VTT/snapshots/c1af215a96934854f42683c19c51391aaee6f962/raw_data/MSRVTT_JSFUSION_test.csv'
video_base_path = '/root/autodl-tmp/LanguageBind/datasets/datasets--friedrichor--MSR-VTT/snapshots/c1af215a96934854f42683c19c51391aaee6f962/MSRVTT_Videos/video'

# æ”»å‡»é…ç½®
attack_methods = ['apgd-ce', 'apgd-dlr', 'fab', 'apgd-t', 'fab-t']
eps = 4/255  # æ”»å‡»å¼ºåº¦
batch_size = 16
test_samples = 2  # æ¯ç§æ”»å‡»æ–¹æ³•æµ‹è¯•çš„æ ·æœ¬æ•°

def compute_metrics(x):
    """è®¡ç®—æ£€ç´¢æŒ‡æ ‡"""
    sx = np.sort(-x, axis=1)
    d = np.diag(-x)
    d = d[:, np.newaxis]
    ind = sx - d
    ind = np.where(ind == 0)
    ind = ind[1]
    metrics = {}
    metrics['R1'] = float(np.sum(ind == 0)) * 100 / len(ind)
    metrics['R5'] = float(np.sum(ind < 5)) * 100 / len(ind)
    metrics['R10'] = float(np.sum(ind < 10)) * 100 / len(ind)
    metrics['MR'] = np.median(ind) + 1
    metrics["MedianR"] = metrics['MR']
    metrics["MeanR"] = np.mean(ind) + 1
    return metrics

class LanguageBindAttackWrapper(torch.nn.Module):
    """ç”¨äºAutoAttackçš„æ¨¡å‹åŒ…è£…å™¨"""
    def __init__(self, model, text_embeddings):
        super().__init__()
        self.model = model 
        # ç¡®ä¿embeddingsæ˜¯float32ç±»å‹
        self.text_embeddings = text_embeddings.float()  # [num_texts, embed_dim]
        
    def forward(self, video_tensor):
        # video_tensor: [batch_size, C, T, H, W]
        # ç¡®ä¿è¾“å…¥æ˜¯float32
        video_tensor = video_tensor.float()
        
        # è·å–è§†é¢‘embedding (ä¸èƒ½ç”¨no_gradï¼Œå› ä¸ºéœ€è¦æ¢¯åº¦)
        video_inputs = {'video': {'pixel_values': video_tensor}}
        video_embeddings = self.model(video_inputs)['video']  # [batch_size, embed_dim]
        
        # è®¡ç®—ç›¸ä¼¼åº¦çŸ©é˜µ [batch_size, num_texts]
        sim_matrix = video_embeddings @ self.text_embeddings.T
        return sim_matrix

def load_msrvtt_test_data(csv_file, video_base_path):
    """åŠ è½½MSR-VTTæµ‹è¯•æ•°æ®"""
    df = pd.read_csv(csv_file)
    
    # æ£€æŸ¥è§†é¢‘æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    valid_indices = []
    for idx, row in df.iterrows():
        video_path = os.path.join(video_base_path, f"{row['video_id']}.mp4")
        if os.path.exists(video_path):
            valid_indices.append(idx)
    
    if len(valid_indices) == 0:
        raise FileNotFoundError(f"åœ¨ {video_base_path} ä¸­æ²¡æœ‰æ‰¾åˆ°ä»»ä½•è§†é¢‘æ–‡ä»¶")
    
    df_valid = df.iloc[valid_indices].reset_index(drop=True)
    
    language_data = df_valid['sentence'].values.tolist()
    video_data = df_valid['video_id'].apply(
        lambda x: os.path.join(video_base_path, f'{x}.mp4')
    ).values.tolist()
    
    print(f"æˆåŠŸåŠ è½½ {len(df_valid)} ä¸ªæœ‰æ•ˆçš„è§†é¢‘-æ–‡æœ¬å¯¹")
    return language_data, video_data, df_valid

def get_embeddings(model, tokenizer, language_data, video_data, modality_transform):
    """è·å–æ‰€æœ‰æ•°æ®çš„embeddings"""
    print("è®¡ç®—embeddings...")
    
    def embed(x: list[list], dtypes: list[str]) -> dict:
        inputs = {}
        for data, dtype in zip(x, dtypes):
            if dtype == 'language':
                inputs['language'] = to_device(
                    tokenizer(data, max_length=77, padding='max_length', 
                             truncation=True, return_tensors='pt'), device)
            elif dtype in modality_transform:
                inputs[dtype] = to_device(modality_transform[dtype](data), device)
            else:
                raise ValueError(f"Unknown dtype: {dtype}")
        
        with torch.no_grad():
            embeddings = model(inputs)
        
        embeddings = {k: v.detach().cpu().numpy() for k, v in embeddings.items()}
        return embeddings
    
    results = defaultdict(lambda: np.empty((0, 768)))
    
    for batch in tqdm(list(zip(
            chunked(language_data, batch_size),
            chunked(video_data, batch_size)
        )), desc="å¤„ç†æ‰¹æ¬¡"):
        
        embeddings = embed(batch, dtypes=['language', 'video'])
        results['language'] = np.concatenate([results['language'], embeddings['language']])
        results['video'] = np.concatenate([results['video'], embeddings['video']])
    
    return results['video'], results['language']

def evaluate_single_attack(attack_method, model, tokenizer, modality_transform, 
                          language_data, video_data, video_embeddings, text_embeddings):
    """è¯„ä¼°å•ä¸ªæ”»å‡»æ–¹æ³•"""
    print(f"\nè¯„ä¼°æ”»å‡»æ–¹æ³•: {attack_method}")
    
    # éšæœºé€‰æ‹©æµ‹è¯•æ ·æœ¬
    total_samples = len(video_data)
    test_indices = random.sample(range(total_samples), min(test_samples, total_samples))
    
    success_count = 0
    total_count = 0
    original_r1_scores = []
    attacked_r1_scores = []
    
    # ä¸ºæ”»å‡»åˆ›å»ºåŒ…è£…æ¨¡å‹
    text_embeddings_tensor = torch.tensor(text_embeddings, dtype=torch.float32).to(device)
    wrapped_model = LanguageBindAttackWrapper(model, text_embeddings_tensor)
    
    for test_idx in tqdm(test_indices, desc=f"æµ‹è¯• {attack_method}"):
        try:
            video_path = video_data[test_idx]
            
            # æ£€æŸ¥è§†é¢‘æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(video_path):
                print(f"è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
                continue
            
            # é¢„å¤„ç†å•ä¸ªè§†é¢‘
            video_tensor_dict = modality_transform['video']([video_path])
            video_tensor_dict = to_device(video_tensor_dict, device)
            video_tensor = video_tensor_dict['pixel_values'].float()  # [1, C, T, H, W] ç¡®ä¿float32
            video_tensor.requires_grad_()
            
            # æ£€æŸ¥tensorå½¢çŠ¶å’Œç±»å‹
            if video_tensor.dim() != 5 or video_tensor.size(0) != 1:
                print(f"è§†é¢‘tensorå½¢çŠ¶å¼‚å¸¸: {video_tensor.shape}")
                continue
            
            # è·å–åŸå§‹é¢„æµ‹
            with torch.no_grad():
                original_sim = wrapped_model(video_tensor.detach())  # [1, num_texts]
                original_pred = torch.argmax(original_sim, dim=-1)  # [1]
            
            # çœŸå®æ ‡ç­¾ï¼ˆå¯¹åº”çš„æ–‡æœ¬ç´¢å¼•ï¼‰
            true_label = torch.tensor([test_idx], dtype=torch.long).to(device)
            
            # æ£€æŸ¥åŸå§‹é¢„æµ‹æ˜¯å¦æ­£ç¡®
            if original_pred.item() != test_idx:
                # å¦‚æœåŸå§‹é¢„æµ‹å°±æ˜¯é”™çš„ï¼Œæˆ‘ä»¬ä»ç„¶è¿›è¡Œæ”»å‡»æµ‹è¯•
                pass
            
            # é…ç½®AutoAttack - ä½¿ç”¨æ›´ç¨³å®šçš„è®¾ç½®
            adversary = AutoAttack(
                wrapped_model, 
                norm='Linf', 
                eps=eps,
                version='custom',
                attacks_to_run=[attack_method],
                verbose=False,
                device=device
            )
            
            # è¿è¡Œæ”»å‡»
            x_adv = adversary.run_standard_evaluation(video_tensor, true_label, bs=1)
            
            # è·å–æ”»å‡»åçš„é¢„æµ‹
            with torch.no_grad():
                adv_sim = wrapped_model(x_adv.detach())  # [1, num_texts]
                adv_pred = torch.argmax(adv_sim, dim=-1)  # [1]
            
            # è®¡ç®—æ£€ç´¢æ€§èƒ½
            original_sim_cpu = original_sim.cpu().numpy()
            adv_sim_cpu = adv_sim.cpu().numpy()
            
            # è®¡ç®—å•æ ·æœ¬çš„R@1 (æ’åæ˜¯å¦ä¸ºç¬¬ä¸€)
            original_rank = np.argsort(-original_sim_cpu[0])
            adv_rank = np.argsort(-adv_sim_cpu[0])
            
            original_r1 = 1.0 if original_rank[0] == test_idx else 0.0
            adv_r1 = 1.0 if adv_rank[0] == test_idx else 0.0
            
            original_r1_scores.append(original_r1)
            attacked_r1_scores.append(adv_r1)
            
            # æ£€æŸ¥æ”»å‡»æ˜¯å¦æˆåŠŸï¼ˆé¢„æµ‹å‘ç”Ÿæ”¹å˜æˆ–æ€§èƒ½ä¸‹é™ï¼‰
            if original_pred.item() != adv_pred.item() or original_r1 > adv_r1:
                success_count += 1
            
            total_count += 1
            
        except Exception as e:
            print(f"å¤„ç†æ ·æœ¬ {test_idx} æ—¶å‡ºé”™: {str(e)}")
            import traceback
            print(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")
            continue
    
    # è®¡ç®—ç»Ÿè®¡ç»“æœ
    if total_count > 0:
        success_rate = success_count / total_count
        original_r1_avg = np.mean(original_r1_scores) * 100
        attacked_r1_avg = np.mean(attacked_r1_scores) * 100
        r1_drop = original_r1_avg - attacked_r1_avg
        
        results = {
            'attack_method': attack_method,
            'success_rate': success_rate,
            'success_count': success_count,
            'total_count': total_count,
            'original_r1': original_r1_avg,
            'attacked_r1': attacked_r1_avg,
            'r1_drop': r1_drop
        }
        
        print(f"{attack_method} ç»“æœ:")
        print(f"  æ”»å‡»æˆåŠŸç‡: {success_rate:.3f} ({success_count}/{total_count})")
        print(f"  åŸå§‹R@1: {original_r1_avg:.2f}%")
        print(f"  æ”»å‡»åR@1: {attacked_r1_avg:.2f}%")
        print(f"  R@1ä¸‹é™: {r1_drop:.2f}%")
        
        return results
    else:
        print(f"{attack_method}: æ²¡æœ‰æœ‰æ•ˆçš„æµ‹è¯•æ ·æœ¬")
        return None

def main():
    print("å¼€å§‹MSR-VTTå¯¹æŠ—æ”»å‡»è¯„ä¼°...")
    
    # åŠ è½½æ¨¡å‹
    print("åŠ è½½LanguageBindæ¨¡å‹...")
    model = LanguageBind(clip_type=clip_type, cache_dir='./cache_dir').to(device)
    model.eval()
    
    tokenizer = LanguageBindImageTokenizer.from_pretrained(
        'lb203/LanguageBind_Image', 
        cache_dir='./cache_dir/tokenizer_cache_dir'
    )
    
    modality_transform = {c: transform_dict[c](model.modality_config[c]) for c in clip_type.keys()}
    
    # åŠ è½½æµ‹è¯•æ•°æ®
    language_data, video_data, df_valid = load_msrvtt_test_data(csv_file, video_base_path)
    
    # è·å–æ‰€æœ‰embeddings
    video_embeddings, text_embeddings = get_embeddings(
        model, tokenizer, language_data, video_data, modality_transform
    )
    
    # è®¡ç®—åŸºçº¿æ€§èƒ½
    print("\nè®¡ç®—åŸºçº¿æ£€ç´¢æ€§èƒ½...")
    sim_matrix = torch.tensor(video_embeddings @ text_embeddings.T)
    baseline_vt = compute_metrics(sim_matrix)
    baseline_tv = compute_metrics(sim_matrix.T)
    
    print(f"åŸºçº¿æ€§èƒ½ - Video-to-Text: R@1={baseline_vt['R1']:.2f}%, R@5={baseline_vt['R5']:.2f}%, R@10={baseline_vt['R10']:.2f}%")
    print(f"åŸºçº¿æ€§èƒ½ - Text-to-Video: R@1={baseline_tv['R1']:.2f}%, R@5={baseline_tv['R5']:.2f}%, R@10={baseline_tv['R10']:.2f}%")
    
    # å¯¹æ¯ç§æ”»å‡»æ–¹æ³•è¿›è¡Œè¯„ä¼°
    all_results = []
    
    for attack_method in attack_methods:
        result = evaluate_single_attack(
            attack_method, model, tokenizer, modality_transform,
            language_data, video_data, video_embeddings, text_embeddings
        )
        if result:
            all_results.append(result)
    
    # ========== ç»“æœæ±‡æ€» ==========
    print("\n" + "="*80)
    print("æ”»å‡»æ–¹æ³•å¯¹æ¯”ç»“æœæ±‡æ€»:")
    print("="*80)
    print(f"{'æ–¹æ³•':<12} {'æˆåŠŸç‡':<8} {'æ ·æœ¬æ•°':<8} {'åŸå§‹R@1':<10} {'æ”»å‡»åR@1':<12} {'R@1ä¸‹é™':<8}")
    print("-"*80)
    
    # æŒ‰R@1ä¸‹é™å¹…åº¦æ’åºï¼ˆæ”»å‡»æ•ˆæœï¼‰
    all_results.sort(key=lambda x: x['r1_drop'], reverse=True)
    
    for result in all_results:
        print(f"{result['attack_method']:<12} "
              f"{result['success_rate']:.3f}    "
              f"{result['success_count']}/{result['total_count']:<3} "
              f"{result['original_r1']:.2f}%      "
              f"{result['attacked_r1']:.2f}%        "
              f"{result['r1_drop']:.2f}%")
    
    # æ‰¾å‡ºæœ€æœ‰æ•ˆçš„æ”»å‡»æ–¹æ³•
    if all_results:
        best_method = all_results[0]
        print(f"\nğŸ† æœ€æœ‰æ•ˆçš„æ”»å‡»æ–¹æ³•: {best_method['attack_method']}")
        print(f"   R@1æ€§èƒ½ä¸‹é™: {best_method['r1_drop']:.2f}%")
        print(f"   æ”»å‡»æˆåŠŸç‡: {best_method['success_rate']:.3f}")
    
    # ä¿å­˜ç»“æœ
    results_data = {
        'baseline_performance': {
            'video_to_text': baseline_vt,
            'text_to_video': baseline_tv
        },
        'attack_results': all_results,
        'config': {
            'eps': eps,
            'test_samples': test_samples,
            'batch_size': batch_size
        }
    }
    
    results_file = 'msrvtt_1k_attack_results.json'
    with open(results_file, 'w', encoding='utf-8') as f:
        json.dump(results_data, f, indent=2, ensure_ascii=False)
    print(f"\nè¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: {results_file}")

if __name__ == "__main__":
    # è®¾ç½®éšæœºç§å­
    torch.manual_seed(42)
    random.seed(42)
    np.random.seed(42)
    
    main()