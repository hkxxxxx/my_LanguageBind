import torch
import pandas as pd
import numpy as np
import os
import pickle
import argparse
from collections import defaultdict
from more_itertools import chunked
from tqdm.auto import tqdm
from autoattack import AutoAttack
from languagebind import LanguageBind, to_device, transform_dict, LanguageBindImageTokenizer
import json
import random
import time
import logging


# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# ========== å‚æ•°é…ç½® ==========
parser = argparse.ArgumentParser(description="MSVDå¯¹æŠ—æ”»å‡»è¯„ä¼°")

# æ¨¡å‹é…ç½®
parser.add_argument('--cache_dir', type=str, default='./cache_dir', help='æ¨¡å‹ç¼“å­˜ç›®å½•')
parser.add_argument('--clip_type', type=str, default='LanguageBind_Video_FT', help='LanguageBindæ¨¡å‹ç±»å‹')

# MSVDæ•°æ®é›†é…ç½®
parser.add_argument('--msvd_root', type=str, default='./', help='MSVDæ•°æ®é›†æ ¹ç›®å½•')
parser.add_argument('--video_dir', type=str, default='./datasets/MSVD_Zero_Shot_QA/videos', help='è§†é¢‘æ–‡ä»¶ç›®å½•')
parser.add_argument('--descriptions_file', type=str, default='./datasets/MSVD_Zero_Shot_QA/AllVideoDescriptions.txt', help='è§†é¢‘æè¿°æ–‡ä»¶è·¯å¾„')
parser.add_argument('--test_list', type=str, default='./datasets/MSVD_Zero_Shot_QA/test_list.txt', help='æµ‹è¯•è§†é¢‘åˆ—è¡¨')

# æ”»å‡»é…ç½®
parser.add_argument('--norm', type=str, default='linf', help='æ”»å‡»èŒƒæ•°: linf, l2')
parser.add_argument('--eps', type=float, default=4., help='æ”»å‡»å¼ºåº¦ (0-255èŒƒå›´)')
parser.add_argument('--alpha', type=float, default=2., help='APGD alphaå‚æ•°')
parser.add_argument('--n_attack_samples', type=int, default=50, help='æ”»å‡»æ ·æœ¬æ•°é‡')
parser.add_argument('--batch_size', type=int, default=16, help='ç‰¹å¾æå–æ‰¹å¤„ç†å¤§å°')
parser.add_argument('--attack_batch_size', type=int, default=4, help='æ”»å‡»æ‰¹å¤„ç†å¤§å°')

# æ”»å‡»æ–¹æ³•é€‰æ‹©
parser.add_argument('--attacks_to_run', type=str, nargs='+', default=None,
                   help='æŒ‡å®šæ”»å‡»æ–¹æ³•ï¼Œé»˜è®¤ä¸ºæ‰€æœ‰ç™½ç›’æ”»å‡»')

# å®éªŒé…ç½®
parser.add_argument('--experiment_name', type=str, default='msvd_attack_eval', help='å®éªŒåç§°')
parser.add_argument('--save_results', type=bool, default=True, help='ä¿å­˜è¯¦ç»†ç»“æœ')
parser.add_argument('--verbose', type=bool, default=True, help='è¯¦ç»†è¾“å‡º')

def load_msvd_descriptions(descriptions_file):
    """åŠ è½½MSVDè§†é¢‘æè¿°æ•°æ®ä»AllVideoDescriptions.txt"""
    logging.info(f"åŠ è½½è§†é¢‘æè¿°æ•°æ®: {descriptions_file}")
    
    try:
        video_descriptions = {}
        with open(descriptions_file, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if line:
                    # åˆ†å‰²è§†é¢‘IDå’Œæè¿°
                    parts = line.split(' ', 1)
                    if len(parts) == 2:
                        video_id, description = parts
                        if video_id not in video_descriptions:
                            video_descriptions[video_id] = []
                        video_descriptions[video_id].append(description)
        
        logging.info(f"æˆåŠŸåŠ è½½ {len(video_descriptions)} ä¸ªè§†é¢‘çš„æè¿°æ•°æ®")
        
        # ç»Ÿè®¡ä¿¡æ¯
        total_descriptions = sum(len(descs) for descs in video_descriptions.values())
        avg_descriptions = total_descriptions / len(video_descriptions)
        logging.info(f"æ€»æè¿°æ•°: {total_descriptions}, å¹³å‡æ¯è§†é¢‘: {avg_descriptions:.1f} ä¸ªæè¿°")
        
        return video_descriptions
        
    except Exception as e:
        logging.error(f"åŠ è½½è§†é¢‘æè¿°æ•°æ®å¤±è´¥: {str(e)}")
        return None

def load_msvd_test_list(test_list_file):
    """åŠ è½½æµ‹è¯•è§†é¢‘åˆ—è¡¨"""
    logging.info(f"åŠ è½½æµ‹è¯•åˆ—è¡¨: {test_list_file}")
    
    try:
        with open(test_list_file, 'r') as f:
            test_videos = [line.strip() for line in f.readlines()]
        logging.info(f"æˆåŠŸåŠ è½½ {len(test_videos)} ä¸ªæµ‹è¯•è§†é¢‘")
        return test_videos
    except Exception as e:
        logging.error(f"åŠ è½½æµ‹è¯•åˆ—è¡¨å¤±è´¥: {str(e)}")
        return None

def prepare_msvd_data_from_descriptions(video_descriptions, test_videos, video_dir):
    """ä»AllVideoDescriptions.txtå‡†å¤‡MSVDæ•°æ®"""
    logging.info("å‡†å¤‡MSVDæ•°æ®...")
    
    valid_videos = []
    valid_captions = []
    video_paths = []
    
    # è°ƒè¯•ä¿¡æ¯
    print(f"DEBUG: test_videosæ•°é‡: {len(test_videos)}")
    print(f"DEBUG: video_descriptionsåŒ…å«è§†é¢‘æ•°: {len(video_descriptions)}")
    
    for video_id in test_videos:
        # æ£€æŸ¥è§†é¢‘æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        video_path_avi = os.path.join(video_dir, f"{video_id}.avi")
        video_path_mp4 = os.path.join(video_dir, f"{video_id}.mp4")
        
        video_path = None
        if os.path.exists(video_path_avi):
            video_path = video_path_avi
        elif os.path.exists(video_path_mp4):
            video_path = video_path_mp4
        else:
            continue
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å¯¹åº”çš„æè¿°æ•°æ®
        if video_id in video_descriptions:
            descriptions_list = video_descriptions[video_id]
            if len(descriptions_list) > 0:
                # é€‰æ‹©ç¬¬ä¸€ä¸ªæè¿°ä½œä¸ºä»£è¡¨æ€§æè¿°
                valid_videos.append(video_id)
                valid_captions.append(descriptions_list[0])
                video_paths.append(video_path)
    
    logging.info(f"æˆåŠŸå‡†å¤‡ {len(valid_videos)} ä¸ªæœ‰æ•ˆçš„è§†é¢‘-æ–‡æœ¬å¯¹ (æ¯ä¸ªè§†é¢‘ä¸€ä¸ªæè¿°)")
    print(f"DEBUG: æœ€ç»ˆè§†é¢‘æ•°: {len(valid_videos)}")
    print(f"DEBUG: æœ€ç»ˆæè¿°æ•°: {len(valid_captions)}")
    
    # æ˜¾ç¤ºä¸€äº›ç¤ºä¾‹
    for i in range(min(3, len(valid_videos))):
        print(f"DEBUG: ç¤ºä¾‹ {i}: {valid_videos[i]} -> {valid_captions[i][:50]}...")
    
    return valid_videos, valid_captions, video_paths

def compute_metrics(sim_matrix):
    """è®¡ç®—æ£€ç´¢æŒ‡æ ‡ - ä¿®å¤ç»´åº¦ä¸åŒ¹é…é—®é¢˜"""
    print(f"DEBUG: sim_matrix shape: {sim_matrix.shape}")
    
    # æ£€æŸ¥çŸ©é˜µæ˜¯å¦ä¸ºæ–¹é˜µï¼Œå¦‚æœä¸æ˜¯ï¼Œè¯´æ˜æœ‰ç»´åº¦é—®é¢˜
    if sim_matrix.shape[0] != sim_matrix.shape[1]:
        print(f"WARNING: ç›¸ä¼¼åº¦çŸ©é˜µä¸æ˜¯æ–¹é˜µ: {sim_matrix.shape}")
    
    ranks = np.argsort(-sim_matrix, axis=1)  # [num_queries, num_targets]
    correct_ranks = []
    
    for i in range(sim_matrix.shape[0]):
        # æ£€æŸ¥ç¬¬iä¸ªæŸ¥è¯¢æ˜¯å¦èƒ½åœ¨ç›®æ ‡ä¸­æ‰¾åˆ°å¯¹åº”çš„ç­”æ¡ˆ
        if i < sim_matrix.shape[1]:  # ç¡®ä¿ç´¢å¼•åœ¨èŒƒå›´å†…
            rank_positions = np.where(ranks[i] == i)[0]
            if len(rank_positions) > 0:
                rank = rank_positions[0]
                correct_ranks.append(rank)
            else:
                # å¦‚æœæ‰¾ä¸åˆ°æ­£ç¡®ç­”æ¡ˆï¼Œè¯´æ˜ç´¢å¼•è¶…å‡ºèŒƒå›´ï¼Œè®¾ä¸ºæœ€å·®æ’å
                print(f"WARNING: æŸ¥è¯¢ {i} æ²¡æœ‰æ‰¾åˆ°å¯¹åº”çš„æ­£ç¡®ç­”æ¡ˆ")
                correct_ranks.append(sim_matrix.shape[1] - 1)  # æœ€å·®æ’å
        else:
            # å¦‚æœæŸ¥è¯¢ç´¢å¼•è¶…å‡ºç›®æ ‡èŒƒå›´ï¼Œè¿™ç§æƒ…å†µä¸‹éœ€è¦é‡æ–°æ€è€ƒæ•°æ®å¯¹åº”å…³ç³»
            print(f"ERROR: æŸ¥è¯¢ç´¢å¼• {i} è¶…å‡ºç›®æ ‡èŒƒå›´ {sim_matrix.shape[1]}")
            correct_ranks.append(sim_matrix.shape[1] - 1)  # æœ€å·®æ’å
    
    if len(correct_ranks) == 0:
        print("ERROR: æ²¡æœ‰æœ‰æ•ˆçš„æ’åæ•°æ®")
        return {
            'R1': 0.0, 'R5': 0.0, 'R10': 0.0, 
            'MR': sim_matrix.shape[1], 'MedianR': sim_matrix.shape[1], 'MeanR': sim_matrix.shape[1]
        }
    
    correct_ranks = np.array(correct_ranks)
    
    # è®¡ç®—æŒ‡æ ‡
    metrics = {}
    metrics['R1'] = float(np.sum(correct_ranks == 0)) * 100 / len(correct_ranks)
    metrics['R5'] = float(np.sum(correct_ranks < 5)) * 100 / len(correct_ranks)
    metrics['R10'] = float(np.sum(correct_ranks < 10)) * 100 / len(correct_ranks)
    metrics['MR'] = np.median(correct_ranks) + 1
    metrics["MedianR"] = metrics['MR']
    metrics["MeanR"] = np.mean(correct_ranks) + 1
    
    print(f"DEBUG: è®¡ç®—äº† {len(correct_ranks)} ä¸ªæœ‰æ•ˆæ’å")
    return metrics

class LanguageBindAttackWrapper(torch.nn.Module):
    """ç”¨äºAutoAttackçš„æ¨¡å‹åŒ…è£…å™¨"""
    def __init__(self, model, text_embeddings, args, logit_scale=100.0):
        super().__init__()
        self.model = model 
        self.text_embeddings = text_embeddings.float()
        self.args = args
        self.logit_scale = logit_scale
        
    def forward(self, video_tensor):
        video_tensor = video_tensor.float()
        video_inputs = {'video': {'pixel_values': video_tensor}}
        video_embeddings = self.model(video_inputs)['video']
        sim_logits = self.logit_scale * video_embeddings @ self.text_embeddings.T
        return sim_logits

def extract_all_features(model, tokenizer, captions, video_paths, modality_transform, batch_size, device):
    """æå–æ‰€æœ‰ç‰¹å¾ - ä¿®å¤tokenizerè°ƒç”¨æ–¹å¼"""
    logging.info("å¼€å§‹æå–æ‰€æœ‰ç‰¹å¾...")
    model.eval()
    
    batch_sequence_output_list = []
    batch_visual_output_list = []
    
    with torch.no_grad():
        # æå–æ–‡æœ¬ç‰¹å¾ - ä¿®å¤tokenizerè°ƒç”¨
        logging.info("æå–æ–‡æœ¬ç‰¹å¾...")
        text_batches = list(chunked(captions, batch_size))
        for batch_texts in tqdm(text_batches, desc="å¤„ç†æ–‡æœ¬æ‰¹æ¬¡"):
            # ğŸ”§ ä¿®å¤ï¼šè¿™é‡Œé‡‡ç”¨ä¸ä½ MSR-VTTè„šæœ¬ç›¸åŒçš„æ–¹å¼
            try:
                # æ–¹å¼1ï¼šæ ‡å‡†transformersæ ¼å¼
                text_tokens = tokenizer(batch_texts, max_length=77, padding='max_length', 
                                      truncation=True, return_tensors='pt')
            except:
                # æ–¹å¼2ï¼šå¦‚æœä¸Šé¢å¤±è´¥ï¼Œå°è¯•é€ä¸ªå¤„ç†
                text_tokens = {'input_ids': [], 'attention_mask': []}
                for text in batch_texts:
                    tokens = tokenizer(text, max_length=77, padding='max_length', 
                                     truncation=True, return_tensors='pt')
                    text_tokens['input_ids'].append(tokens['input_ids'])
                    text_tokens['attention_mask'].append(tokens['attention_mask'])
                text_tokens['input_ids'] = torch.cat(text_tokens['input_ids'], dim=0)
                text_tokens['attention_mask'] = torch.cat(text_tokens['attention_mask'], dim=0)
            
            text_tokens = to_device(text_tokens, device)
            
            # ä½¿ç”¨LanguageBindçš„æ–‡æœ¬ç¼–ç 
            text_inputs = {'language': text_tokens}
            text_embeddings = model(text_inputs)['language']
            
            batch_sequence_output_list.append(text_embeddings.cpu())
        
        # æå–è§†é¢‘ç‰¹å¾
        logging.info("æå–è§†é¢‘ç‰¹å¾...")
        video_batches = list(chunked(video_paths, batch_size))
        for batch_videos in tqdm(video_batches, desc="å¤„ç†è§†é¢‘æ‰¹æ¬¡"):
            try:
                video_tensor_dict = modality_transform['video'](batch_videos)
                video_tensor_dict = to_device(video_tensor_dict, device)
                
                video_inputs = {'video': video_tensor_dict}
                video_embeddings = model(video_inputs)['video']
                
                batch_visual_output_list.append(video_embeddings.cpu())
                
            except Exception as e:
                logging.warning(f"è·³è¿‡è§†é¢‘æ‰¹æ¬¡: {str(e)}")
                dummy_embeddings = torch.zeros(len(batch_videos), 768)
                batch_visual_output_list.append(dummy_embeddings)
                continue
    
    # åˆå¹¶æ‰€æœ‰ç‰¹å¾
    all_text_embeddings = torch.cat(batch_sequence_output_list, dim=0)
    all_video_embeddings = torch.cat(batch_visual_output_list, dim=0)
    
    logging.info(f"æ–‡æœ¬ç‰¹å¾å½¢çŠ¶: {all_text_embeddings.shape}")
    logging.info(f"è§†é¢‘ç‰¹å¾å½¢çŠ¶: {all_video_embeddings.shape}")
    
    return all_text_embeddings.numpy(), all_video_embeddings.numpy()

def compute_full_similarity_matrix(text_embeddings, video_embeddings, logit_scale=100.0):
    """è®¡ç®—å®Œæ•´ç›¸ä¼¼åº¦çŸ©é˜µ - æ·»åŠ è°ƒè¯•ä¿¡æ¯"""
    logging.info("è®¡ç®—å®Œæ•´ç›¸ä¼¼åº¦çŸ©é˜µ...")
    
    print(f"DEBUG: text_embeddings shape: {text_embeddings.shape}")
    print(f"DEBUG: video_embeddings shape: {video_embeddings.shape}")
    
    # å¯¹é½æ£€ç´¢è„šæœ¬: logit_scale * text @ video.T (æ³¨æ„è¿™é‡Œæ˜¯textåœ¨å‰)
    sim_matrix = logit_scale * text_embeddings @ video_embeddings.T  # [num_texts, num_videos]
    
    logging.info(f"ç›¸ä¼¼åº¦çŸ©é˜µå½¢çŠ¶: {sim_matrix.shape}")
    print(f"DEBUG: æœ€ç»ˆç›¸ä¼¼åº¦çŸ©é˜µå½¢çŠ¶: {sim_matrix.shape}")
    
    # æ£€æŸ¥æ˜¯å¦ä¸ºæ–¹é˜µ
    if sim_matrix.shape[0] != sim_matrix.shape[1]:
        logging.warning(f"ç›¸ä¼¼åº¦çŸ©é˜µä¸æ˜¯æ–¹é˜µ: {sim_matrix.shape[0]} x {sim_matrix.shape[1]}")
        logging.info("è¿™å¯èƒ½æ˜¯æ­£å¸¸çš„ï¼Œå¦‚æœæ–‡æœ¬æ•°é‡ä¸è§†é¢‘æ•°é‡ä¸åŒ")
    
    return sim_matrix

def evaluate_baseline_retrieval(sim_matrix):
    """è¯„ä¼°åŸºçº¿æ£€ç´¢æ€§èƒ½ - ä¸“é—¨å¤„ç†MSVDçš„æ–¹é˜µæƒ…å†µ"""
    logging.info("è¯„ä¼°åŸºçº¿æ£€ç´¢æ€§èƒ½...")
    
    print(f"DEBUG: åŸºçº¿ç›¸ä¼¼åº¦çŸ©é˜µå½¢çŠ¶: {sim_matrix.shape}")
    
    # æ£€æŸ¥çŸ©é˜µç»´åº¦
    num_texts, num_videos = sim_matrix.shape
    
    if num_texts == num_videos:
        # æ–¹é˜µæƒ…å†µï¼šæ ‡å‡†çš„è§†é¢‘-æ–‡æœ¬é…å¯¹è¯„ä¼°
        logging.info("æ£€æµ‹åˆ°æ–¹é˜µï¼Œè¿›è¡Œæ ‡å‡†çš„é…å¯¹è¯„ä¼°")
        tv_metrics = compute_metrics(sim_matrix)      # Text-to-Video
        vt_metrics = compute_metrics(sim_matrix.T)   # Video-to-Text
        
        # æ£€æŸ¥æ€§èƒ½æ˜¯å¦åˆç†
        if tv_metrics['R1'] < 1.0 and vt_metrics['R1'] < 1.0:
            logging.error("âš ï¸  åŸºçº¿æ€§èƒ½å¼‚å¸¸ä½ï¼Œå¯èƒ½å­˜åœ¨æ•°æ®å¯¹åº”é—®é¢˜!")
            logging.error("å»ºè®®æ£€æŸ¥:")
            logging.error("1. è§†é¢‘å’Œæ–‡æœ¬çš„å¯¹åº”å…³ç³»æ˜¯å¦æ­£ç¡®")
            logging.error("2. LanguageBindæ¨¡å‹æ˜¯å¦æ­£ç¡®åŠ è½½")
            logging.error("3. æ•°æ®é¢„å¤„ç†æ˜¯å¦æœ‰é—®é¢˜")
            
    else:
        # éæ–¹é˜µæƒ…å†µï¼šè¿™è¡¨æ˜æ•°æ®æœ‰é—®é¢˜
        logging.error(f"âŒ æ£€æµ‹åˆ°éæ–¹é˜µ ({num_texts} texts, {num_videos} videos)")
        logging.error("è¿™é€šå¸¸è¡¨æ˜æ•°æ®å‡†å¤‡æœ‰é—®é¢˜ï¼Œæ¯ä¸ªè§†é¢‘åº”è¯¥å¯¹åº”ä¸€ä¸ªæ–‡æœ¬")
        
        # å¼ºåˆ¶åˆ›å»ºæ–¹é˜µè¿›è¡Œè¯„ä¼°
        min_size = min(num_texts, num_videos)
        logging.warning(f"å¼ºåˆ¶ä½¿ç”¨å‰ {min_size} ä¸ªæ ·æœ¬åˆ›å»ºæ–¹é˜µè¿›è¡Œè¯„ä¼°")
        
        square_sim = sim_matrix[:min_size, :min_size]
        tv_metrics = compute_metrics(square_sim)
        vt_metrics = compute_metrics(square_sim.T)
    
    # å¯¹é½æ£€ç´¢è„šæœ¬çš„æ—¥å¿—æ ¼å¼
    logging.info("MSVD Text-to-Video:")
    logging.info(f'\t>>>  R@1: {tv_metrics["R1"]:.1f} - R@5: {tv_metrics["R5"]:.1f} - R@10: {tv_metrics["R10"]:.1f} - Median R: {tv_metrics["MR"]:.1f} - Mean R: {tv_metrics["MeanR"]:.1f}')
    
    logging.info("MSVD Video-to-Text:")
    logging.info(f'\t>>>  V2T$R@1: {vt_metrics["R1"]:.1f} - V2T$R@5: {vt_metrics["R5"]:.1f} - V2T$R@10: {vt_metrics["R10"]:.1f} - V2T$Median R: {vt_metrics["MR"]:.1f} - V2T$Mean R: {vt_metrics["MeanR"]:.1f}')
    
    # æ€§èƒ½æ£€æŸ¥
    if tv_metrics['R1'] > 10.0 or vt_metrics['R1'] > 10.0:
        logging.info("âœ… åŸºçº¿æ€§èƒ½çœ‹èµ·æ¥æ­£å¸¸ï¼Œå¯ä»¥è¿›è¡Œæ”»å‡»è¯„ä¼°")
    else:
        logging.warning(f"âš ï¸  åŸºçº¿æ€§èƒ½è¾ƒä½ (T2V R@1: {tv_metrics['R1']:.1f}%, V2T R@1: {vt_metrics['R1']:.1f}%)")
        logging.warning("æ”»å‡»æ•ˆæœå¯èƒ½ä¸æ˜æ˜¾")
    
    return tv_metrics, vt_metrics

def evaluate_attack_on_subset(attack_method, model, modality_transform, video_paths, 
                             text_embeddings, baseline_sim_matrix, args):
    """è¯„ä¼°æ”»å‡»æ•ˆæœ - ç®€åŒ–ç‰ˆæœ¬ï¼Œä¸“æ³¨äºè§£å†³tokenizeré—®é¢˜"""
    logging.info(f"\nå¼€å§‹è¯„ä¼°æ”»å‡»æ–¹æ³•: {attack_method}")
    
    device = next(model.parameters()).device
    total_samples = len(video_paths)
    
    # éšæœºé€‰æ‹©æ”»å‡»æ ·æœ¬
    attack_indices = random.sample(range(total_samples), 
                                 min(args.n_attack_samples, total_samples))
    
    logging.info(f"ä½¿ç”¨å­é›†è¿›è¡Œæ”»å‡» ({len(attack_indices)} ä¸ªæ ·æœ¬)")
    logging.info(f"æ¯ä¸ªæ”»å‡»è§†é¢‘å°†åœ¨å…¨éƒ¨ {len(text_embeddings)} ä¸ªæ–‡æœ¬ä¸­è¿›è¡Œæ£€ç´¢")
    
    # ä¸ºæ”»å‡»åˆ›å»ºåŒ…è£…æ¨¡å‹
    text_embeddings_tensor = torch.tensor(text_embeddings, dtype=torch.float32).to(device)
    wrapped_model = LanguageBindAttackWrapper(model, text_embeddings_tensor, args)
    
    # å­˜å‚¨æ”»å‡»ç»“æœ
    all_original_video_embeddings = []
    all_attacked_video_embeddings = []
    all_attack_labels = []
    
    total_attack_time = 0
    total_valid_samples = 0
    
    # æŒ‰æ‰¹æ¬¡å¤„ç†æ”»å‡»
    batch_size = args.attack_batch_size
    num_batches = (len(attack_indices) + batch_size - 1) // batch_size
    
    logging.info(f"å°†åˆ† {num_batches} ä¸ªæ‰¹æ¬¡è¿›è¡Œæ”»å‡»ï¼Œæ¯æ‰¹æœ€å¤š {batch_size} ä¸ªæ ·æœ¬")
    
    for batch_idx in tqdm(range(num_batches), desc=f"æ”»å‡»æ‰¹æ¬¡ {attack_method}"):
        start_idx = batch_idx * batch_size
        end_idx = min(start_idx + batch_size, len(attack_indices))
        batch_indices = attack_indices[start_idx:end_idx]
        
        # å‡†å¤‡å½“å‰æ‰¹æ¬¡çš„æ•°æ®
        batch_videos = []
        batch_labels = []
        
        for attack_idx in batch_indices:
            try:
                video_path = video_paths[attack_idx]
                if not os.path.exists(video_path):
                    continue
                
                # é¢„å¤„ç†è§†é¢‘
                video_tensor_dict = modality_transform['video']([video_path])
                video_tensor_dict = to_device(video_tensor_dict, device)
                video_tensor = video_tensor_dict['pixel_values'].float()
                
                batch_videos.append(video_tensor.squeeze(0))
                batch_labels.append(attack_idx)
                
            except Exception as e:
                if args.verbose and batch_idx < 5:
                    logging.warning(f"è·³è¿‡æ ·æœ¬ {attack_idx}: {str(e)}")
                continue
        
        if len(batch_videos) == 0:
            continue
        
        # è½¬æ¢ä¸ºtensor
        x_batch = torch.stack(batch_videos).to(device)
        y_batch = torch.tensor(batch_labels, dtype=torch.long).to(device)
        
        # è·å–åŸå§‹è§†é¢‘embeddings
        with torch.no_grad():
            original_video_inputs = {'video': {'pixel_values': x_batch}}
            original_video_embeddings = model(original_video_inputs)['video']
        
        # è¿è¡Œæ”»å‡»
        adversary = AutoAttack(
            wrapped_model, 
            norm=args.norm.replace('l', 'L'),
            eps=args.eps,
            version='custom',
            attacks_to_run=[attack_method],
            alpha=args.alpha,
            verbose=False
        )
        
        start_time = time.time()
        x_adv, y_adv = adversary.run_standard_evaluation(
            x_batch, y_batch, bs=len(x_batch), return_labels=True
        )
        batch_attack_time = time.time() - start_time
        
        # è·å–æ”»å‡»åçš„è§†é¢‘embeddings
        with torch.no_grad():
            adv_video_inputs = {'video': {'pixel_values': x_adv}}
            adv_video_embeddings = model(adv_video_inputs)['video']
        
        # ä¿å­˜embeddings
        all_original_video_embeddings.append(original_video_embeddings.cpu().numpy())
        all_attacked_video_embeddings.append(adv_video_embeddings.cpu().numpy())
        all_attack_labels.extend(batch_labels)
        
        total_attack_time += batch_attack_time
        total_valid_samples += len(batch_labels)
        
        # æ¸…ç†å†…å­˜
        del x_batch, y_batch, x_adv, y_adv, original_video_embeddings, adv_video_embeddings, batch_videos
        torch.cuda.empty_cache()
        
        # è¾“å‡ºè¿›åº¦
        if (batch_idx + 1) % 5 == 0 or (batch_idx + 1) == num_batches:
            logging.info(f"  å®Œæˆ: {batch_idx + 1}/{num_batches} æ‰¹æ¬¡, "
                        f"ç´¯è®¡æ ·æœ¬: {total_valid_samples}, "
                        f"ç´¯è®¡è€—æ—¶: {total_attack_time:.1f}s")
    
    if total_valid_samples == 0:
        logging.error(f"{attack_method}: æ²¡æœ‰æœ‰æ•ˆçš„æ”»å‡»æ ·æœ¬")
        return None
    
    # åœ¨å…¨é›†ä¸Šè¿›è¡Œæ£€ç´¢è¯„ä¼°
    logging.info(f"å¼€å§‹åœ¨å…¨é›†ä¸Šè¯„ä¼° {total_valid_samples} ä¸ªæ”»å‡»æ ·æœ¬çš„æ£€ç´¢æ€§èƒ½...")
    
    # åˆå¹¶æ‰€æœ‰æ”»å‡»æ ·æœ¬çš„embeddings
    all_original_embeddings = np.concatenate(all_original_video_embeddings, axis=0)
    all_attacked_embeddings = np.concatenate(all_attacked_video_embeddings, axis=0)
    
    # è®¡ç®—åœ¨å…¨é›†ä¸Šçš„ç›¸ä¼¼åº¦çŸ©é˜µ
    original_sim_matrix = 100.0 * all_original_embeddings @ text_embeddings.T
    attacked_sim_matrix = 100.0 * all_attacked_embeddings @ text_embeddings.T
    
    # è®¡ç®—æ¯ä¸ªæ”»å‡»æ ·æœ¬çš„æ£€ç´¢æ€§èƒ½
    original_ranks = []
    attacked_ranks = []
    
    for i, true_label in enumerate(all_attack_labels):
        # åŸå§‹è§†é¢‘çš„æ£€ç´¢æ’å
        original_similarities = original_sim_matrix[i, :]
        original_sorted_indices = np.argsort(-original_similarities)
        original_rank = np.where(original_sorted_indices == true_label)[0][0]
        original_ranks.append(original_rank)
        
        # æ”»å‡»åè§†é¢‘çš„æ£€ç´¢æ’å
        attacked_similarities = attacked_sim_matrix[i, :]
        attacked_sorted_indices = np.argsort(-attacked_similarities)
        attacked_rank = np.where(attacked_sorted_indices == true_label)[0][0]
        attacked_ranks.append(attacked_rank)
    
    original_ranks = np.array(original_ranks)
    attacked_ranks = np.array(attacked_ranks)
    
    # è®¡ç®—æ£€ç´¢æŒ‡æ ‡
    def compute_retrieval_metrics(ranks):
        metrics = {}
        metrics['R1'] = float(np.sum(ranks == 0)) * 100 / len(ranks)
        metrics['R5'] = float(np.sum(ranks < 5)) * 100 / len(ranks)
        metrics['R10'] = float(np.sum(ranks < 10)) * 100 / len(ranks)
        metrics['MR'] = np.median(ranks) + 1
        metrics['MeanR'] = np.mean(ranks) + 1
        return metrics
    
    original_metrics = compute_retrieval_metrics(original_ranks)
    attacked_metrics = compute_retrieval_metrics(attacked_ranks)
    
    # è®¡ç®—æ”»å‡»æ•ˆæœ
    rank_degradation = np.mean(attacked_ranks - original_ranks)
    successful_attacks = np.sum(attacked_ranks > original_ranks)
    attack_success_rate = successful_attacks / len(original_ranks)
    
    # å¯¹æ¯”åŸºçº¿æ€§èƒ½
    baseline_ranks = []
    for true_label in all_attack_labels:
        baseline_similarities = baseline_sim_matrix[true_label, :]
        baseline_sorted_indices = np.argsort(-baseline_similarities)
        baseline_rank = np.where(baseline_sorted_indices == true_label)[0][0]
        baseline_ranks.append(baseline_rank)
    
    baseline_ranks = np.array(baseline_ranks)
    baseline_metrics = compute_retrieval_metrics(baseline_ranks)
    
    # æ•´ç†ç»“æœ
    results = {
        'attack_method': attack_method,
        'total_samples': total_valid_samples,
        'attack_time': total_attack_time,
        'avg_time_per_sample': total_attack_time / total_valid_samples,
        
        # åŸºçº¿æ€§èƒ½
        'baseline_r1': baseline_metrics['R1'],
        'baseline_r5': baseline_metrics['R5'],
        'baseline_r10': baseline_metrics['R10'],
        
        # æ”»å‡»å‰æ€§èƒ½
        'original_r1': original_metrics['R1'],
        'original_r5': original_metrics['R5'],
        'original_r10': original_metrics['R10'],
        'original_mean_rank': original_metrics['MeanR'],
        
        # æ”»å‡»åæ€§èƒ½
        'attacked_r1': attacked_metrics['R1'],
        'attacked_r5': attacked_metrics['R5'],
        'attacked_r10': attacked_metrics['R10'],
        'attacked_mean_rank': attacked_metrics['MeanR'],
        
        # æ”»å‡»æ•ˆæœæŒ‡æ ‡
        'r1_drop': original_metrics['R1'] - attacked_metrics['R1'],
        'r5_drop': original_metrics['R5'] - attacked_metrics['R5'],
        'r10_drop': original_metrics['R10'] - attacked_metrics['R10'],
        'mean_rank_increase': attacked_metrics['MeanR'] - original_metrics['MeanR'],
        'attack_success_rate': attack_success_rate,
        'mean_rank_degradation': rank_degradation
    }
    
    # è¾“å‡ºè¯¦ç»†ç»“æœ
    logging.info(f"\n{attack_method} å…¨é›†æ£€ç´¢è¯„ä¼°ç»“æœ:")
    logging.info(f"  æ”»å‡»æ ·æœ¬æ•°: {total_valid_samples}")
    logging.info(f"  æ€»æ”»å‡»è€—æ—¶: {total_attack_time:.1f}ç§’")
    logging.info(f"  å¹³å‡æ¯æ ·æœ¬: {total_attack_time / total_valid_samples:.2f}ç§’")
    logging.info(f"")
    logging.info(f"  åŸºçº¿æ£€ç´¢æ€§èƒ½:")
    logging.info(f"    R@1: {baseline_metrics['R1']:.2f}% | R@5: {baseline_metrics['R5']:.2f}% | R@10: {baseline_metrics['R10']:.2f}%")
    logging.info(f"")
    logging.info(f"  æ”»å‡»å‰æ£€ç´¢æ€§èƒ½:")
    logging.info(f"    R@1: {original_metrics['R1']:.2f}% | R@5: {original_metrics['R5']:.2f}% | R@10: {original_metrics['R10']:.2f}%")
    logging.info(f"")
    logging.info(f"  æ”»å‡»åæ£€ç´¢æ€§èƒ½:")
    logging.info(f"    R@1: {attacked_metrics['R1']:.2f}% | R@5: {attacked_metrics['R5']:.2f}% | R@10: {attacked_metrics['R10']:.2f}%")
    logging.info(f"")
    logging.info(f"  æ”»å‡»æ•ˆæœ:")
    logging.info(f"    R@1ä¸‹é™: {original_metrics['R1'] - attacked_metrics['R1']:.2f}%")
    logging.info(f"    R@5ä¸‹é™: {original_metrics['R5'] - attacked_metrics['R5']:.2f}%")
    logging.info(f"    R@10ä¸‹é™: {original_metrics['R10'] - attacked_metrics['R10']:.2f}%")
    logging.info(f"    å¹³å‡æ’åæ¶åŒ–: {rank_degradation:.2f}")
    logging.info(f"    æ”»å‡»æˆåŠŸç‡: {attack_success_rate:.3f}")
    
    return results

def main():
    args = parser.parse_args()
    
    # è®¾ç½®éšæœºç§å­
    torch.manual_seed(42)
    np.random.seed(42)
    random.seed(42)
    
    # è½¬æ¢å‚æ•°èŒƒå›´
    args.eps = args.eps / 255
    args.alpha = args.alpha / 255
    
    logging.info(f"å®éªŒé…ç½®:\n{'-' * 50}")
    for arg, value in vars(args).items():
        logging.info(f"{arg}: {value}")
    logging.info(f"{'-' * 50}")
    
    # è®¾å¤‡é…ç½®
    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
    logging.info(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    # ç¡®å®šæ”»å‡»æ–¹æ³•
    if args.attacks_to_run is not None:
        attacks_to_run = args.attacks_to_run
    else:
        # attacks_to_run = ['apgd-ce', 'apgd-dlr', 'fab', 'apgd-t', 'fab-t']
        attacks_to_run = ['apgd-t']
    
    logging.info(f'è®¡åˆ’è¿è¡Œçš„æ”»å‡»æ–¹æ³•: {attacks_to_run}')
    
    # åŠ è½½LanguageBindæ¨¡å‹
    logging.info("åŠ è½½LanguageBindæ¨¡å‹...")
    clip_type = {'video': args.clip_type}
    model = LanguageBind(clip_type=clip_type, cache_dir=args.cache_dir).to(device)
    model.eval()
    
    tokenizer = LanguageBindImageTokenizer.from_pretrained(
        'lb203/LanguageBind_Image', 
        cache_dir=os.path.join(args.cache_dir, 'tokenizer_cache_dir')
    )
    
    modality_transform = {c: transform_dict[c](model.modality_config[c]) for c in clip_type.keys()}
    
    # åŠ è½½MSVDæ•°æ®
    video_descriptions = load_msvd_descriptions(args.descriptions_file)
    if video_descriptions is None:
        return
    
    test_videos = load_msvd_test_list(args.test_list)
    if test_videos is None:
        return
    
    video_ids, captions, video_paths = prepare_msvd_data_from_descriptions(
        video_descriptions, test_videos, args.video_dir
    )
    
    if len(video_paths) == 0:
        logging.error("æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„è§†é¢‘æ–‡ä»¶")
        return
    
    # æå–æ‰€æœ‰ç‰¹å¾å¹¶è®¡ç®—åŸºçº¿æ€§èƒ½
    text_embeddings, video_embeddings = extract_all_features(
        model, tokenizer, captions, video_paths, 
        modality_transform, args.batch_size, device
    )
    
    # è®¡ç®—å®Œæ•´ç›¸ä¼¼åº¦çŸ©é˜µ
    sim_matrix = compute_full_similarity_matrix(text_embeddings, video_embeddings)
    
    # è¯„ä¼°åŸºçº¿æ£€ç´¢æ€§èƒ½
    baseline_tv_metrics, baseline_vt_metrics = evaluate_baseline_retrieval(sim_matrix)
    
    # å¯¹æ¯ç§æ”»å‡»æ–¹æ³•è¿›è¡Œè¯„ä¼°
    all_attack_results = []
    
    for attack_method in attacks_to_run:
        try:
            result = evaluate_attack_on_subset(
                attack_method, model, modality_transform, video_paths,
                text_embeddings, sim_matrix, args
            )
            if result:
                all_attack_results.append(result)
        except Exception as e:
            logging.error(f"æ”»å‡»æ–¹æ³• {attack_method} æ‰§è¡Œå¤±è´¥: {str(e)}")
            continue
    
    # ç»“æœæ±‡æ€»
    logging.info("\n" + "="*100)
    logging.info("MSVDæ”»å‡»è¯„ä¼°ç»“æœæ±‡æ€»:")
    logging.info("="*100)
    
    if all_attack_results:
        # æŒ‰R@1ä¸‹é™æ’åº
        all_attack_results.sort(key=lambda x: x.get('r1_drop', 0), reverse=True)
        
        logging.info(f"{'æ”»å‡»æ–¹æ³•':<12} {'æ ·æœ¬æ•°':<6} {'åŸºçº¿R@1':<8} {'æ”»å‡»å‰R@1':<10} {'æ”»å‡»åR@1':<10} {'R@1ä¸‹é™':<8} {'R@5ä¸‹é™':<8} {'æˆåŠŸç‡':<8}")
        logging.info("-"*100)
        
        for result in all_attack_results:
            logging.info(f"{result['attack_method']:<12} "
                        f"{result['total_samples']:<6} "
                        f"{result.get('baseline_r1', 0):.1f}%     "
                        f"{result.get('original_r1', 0):.1f}%       "
                        f"{result.get('attacked_r1', 0):.1f}%       "
                        f"{result.get('r1_drop', 0):.1f}%    "
                        f"{result.get('r5_drop', 0):.1f}%    "
                        f"{result.get('attack_success_rate', 0):.3f}")
        
        # æ‰¾å‡ºæœ€æœ‰æ•ˆçš„æ”»å‡»æ–¹æ³•
        best_method = all_attack_results[0]
        logging.info(f"\nğŸ† æœ€æœ‰æ•ˆçš„æ”»å‡»æ–¹æ³•: {best_method['attack_method']}")
        logging.info(f"   R@1ä¸‹é™: {best_method.get('r1_drop', 0):.2f}%")
        logging.info(f"   R@5ä¸‹é™: {best_method.get('r5_drop', 0):.2f}%")
        logging.info(f"   æ”»å‡»æˆåŠŸç‡: {best_method.get('attack_success_rate', 0):.3f}")
        logging.info(f"   å¹³å‡æ’åæ¶åŒ–: {best_method.get('mean_rank_degradation', 0):.1f}")
    
    # ä¿å­˜ç»“æœ
    if args.save_results:
        results_data = {
            'experiment_config': vars(args),
            'baseline_performance': {
                'text_to_video': baseline_tv_metrics,
                'video_to_text': baseline_vt_metrics
            },
            'attack_results': all_attack_results,
            'summary': {
                'best_attack': best_method['attack_method'] if all_attack_results else None,
                'max_r1_drop': best_method.get('r1_drop', 0) if all_attack_results else 0,
                'max_r5_drop': best_method.get('r5_drop', 0) if all_attack_results else 0,
                'max_success_rate': best_method.get('attack_success_rate', 0) if all_attack_results else 0
            } if all_attack_results else {}
        }
        
        timestamp = time.strftime("%Y-%m-%d_%H-%M-%S")
        results_file = f'{args.experiment_name}_{args.norm}_eps{int(args.eps*255)}_{timestamp}.json'
        
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(results_data, f, indent=2, ensure_ascii=False)
        logging.info(f"\nè¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: {results_file}")

if __name__ == "__main__":
    # ä½¿ç”¨ç¤ºä¾‹
    print("MSVDå¯¹æŠ—æ”»å‡»è¯„ä¼°è„šæœ¬")
    print("ä½¿ç”¨ç¤ºä¾‹:")
    print("  python msvd_complete_script.py --descriptions_file ./AllVideoDescriptions.txt --video_dir ./videos --test_list ./test_list.txt --n_attack_samples 10")
    print("")
    
    main()