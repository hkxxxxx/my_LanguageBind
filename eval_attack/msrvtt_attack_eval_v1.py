import torch
import pandas as pd
import numpy as np
import os
import argparse
from collections import defaultdict
from more_itertools import chunked
from tqdm.auto import tqdm
from autoattack import AutoAttack
from languagebind import LanguageBind, to_device, transform_dict, LanguageBindImageTokenizer
import json
import random
import time
import logging

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# ========== å‚æ•°é…ç½® (å¯¹é½CLIP RobustBench) ==========
parser = argparse.ArgumentParser(description="MSR-VTTå¯¹æŠ—æ”»å‡»è¯„ä¼° - å…¨æ•°æ®é›†ç‰ˆæœ¬")

# æ¨¡å‹é…ç½®
parser.add_argument('--cache_dir', type=str, default='./cache_dir', help='æ¨¡å‹ç¼“å­˜ç›®å½•')
parser.add_argument('--clip_type', type=str, default='LanguageBind_Video_FT', help='LanguageBindæ¨¡å‹ç±»å‹')

# æ•°æ®é›†é…ç½®  
parser.add_argument('--csv_file', type=str, default='/root/autodl-tmp/LanguageBind/datasets/datasets--friedrichor--MSR-VTT/snapshots/c1af215a96934854f42683c19c51391aaee6f962/raw_data/MSRVTT_JSFUSION_test.csv', help='MSR-VTTæµ‹è¯•é›†CSVæ–‡ä»¶')
parser.add_argument('--video_base_path', type=str, default='/root/autodl-tmp/LanguageBind/datasets/datasets--friedrichor--MSR-VTT/snapshots/c1af215a96934854f42683c19c51391aaee6f962/MSRVTT_Videos/video', help='è§†é¢‘æ–‡ä»¶åŸºç¡€è·¯å¾„')

# æ”»å‡»é…ç½® (å¯¹é½RobustBenchå‚æ•°)
parser.add_argument('--norm', type=str, default='linf', help='æ”»å‡»èŒƒæ•°: linf, l2')
parser.add_argument('--eps', type=float, default=4., help='æ”»å‡»å¼ºåº¦ (0-255èŒƒå›´)')
parser.add_argument('--alpha', type=float, default=2., help='APGD alphaå‚æ•°')
parser.add_argument('--n_attack_samples', type=int, default=50, help='æ¯ç§æ”»å‡»æ–¹æ³•çš„æµ‹è¯•æ ·æœ¬æ•°ï¼Œè®¾ä¸º-1åˆ™ä½¿ç”¨å…¨æ•°æ®é›†')
parser.add_argument('--batch_size', type=int, default=16, help='ç‰¹å¾æå–æ‰¹å¤„ç†å¤§å°')
parser.add_argument('--attack_batch_size', type=int, default=4, help='æ”»å‡»æ—¶çš„æ‰¹å¤„ç†å¤§å°')
parser.add_argument('--full_dataset_attack', type=bool, default=False, help='æ˜¯å¦åœ¨å…¨æ•°æ®é›†ä¸Šè¿›è¡Œæ”»å‡»')

# æ”»å‡»æ–¹æ³•é€‰æ‹©
parser.add_argument('--blackbox_only', type=bool, default=False, help='ä»…è¿è¡Œé»‘ç›’æ”»å‡»')
parser.add_argument('--attacks_to_run', type=str, nargs='+', default=None, 
                   help='æŒ‡å®šè¿è¡Œçš„æ”»å‡»æ–¹æ³•ï¼Œé»˜è®¤ä¸ºæ‰€æœ‰ç™½ç›’æ”»å‡»')

# å®éªŒé…ç½®
parser.add_argument('--experiment_name', type=str, default='msrvtt_full_attack_eval', help='å®éªŒåç§°')
parser.add_argument('--save_results', type=bool, default=True, help='ä¿å­˜è¯¦ç»†ç»“æœ')
parser.add_argument('--verbose', type=bool, default=True, help='è¯¦ç»†è¾“å‡º')

def compute_metrics(sim_matrix):
    """
    è®¡ç®—æ£€ç´¢æŒ‡æ ‡ - å¯¹é½åŸå§‹æ£€ç´¢è„šæœ¬
    sim_matrix: [num_queries, num_targets]
    """
    # æŒ‰ç›¸ä¼¼åº¦é™åºæ’åºï¼Œè·å¾—æ’å
    ranks = np.argsort(-sim_matrix, axis=1)  # [num_queries, num_targets]
    
    # è®¡ç®—æ¯ä¸ªæŸ¥è¯¢çš„æ­£ç¡®ç­”æ¡ˆæ’å (å‡è®¾ç¬¬iä¸ªæŸ¥è¯¢å¯¹åº”ç¬¬iä¸ªç›®æ ‡)
    correct_ranks = []
    for i in range(sim_matrix.shape[0]):
        # æ‰¾åˆ°æ­£ç¡®ç­”æ¡ˆ(ç¬¬iä¸ªç›®æ ‡)åœ¨æ’åºä¸­çš„ä½ç½®
        rank = np.where(ranks[i] == i)[0][0]
        correct_ranks.append(rank)
    
    correct_ranks = np.array(correct_ranks)
    
    # è®¡ç®—æŒ‡æ ‡
    metrics = {}
    metrics['R1'] = float(np.sum(correct_ranks == 0)) * 100 / len(correct_ranks)
    metrics['R5'] = float(np.sum(correct_ranks < 5)) * 100 / len(correct_ranks)
    metrics['R10'] = float(np.sum(correct_ranks < 10)) * 100 / len(correct_ranks)
    metrics['MR'] = np.median(correct_ranks) + 1
    metrics["MedianR"] = metrics['MR']
    metrics["MeanR"] = np.mean(correct_ranks) + 1
    
    return metrics

class LanguageBindAttackWrapper(torch.nn.Module):
    """
    ç”¨äºAutoAttackçš„æ¨¡å‹åŒ…è£…å™¨ - å¯¹é½æ£€ç´¢è„šæœ¬çš„ç›¸ä¼¼åº¦è®¡ç®—
    """
    def __init__(self, model, text_embeddings, args, logit_scale=100.0):
        super().__init__()
        self.model = model 
        self.text_embeddings = text_embeddings.float()  # [num_texts, embed_dim]
        self.args = args
        self.logit_scale = logit_scale  # æ¨¡æ‹ŸåŸè„šæœ¬ä¸­çš„logit_scale
        
    def forward(self, video_tensor):
        """
        å‰å‘ä¼ æ’­ - å¯¹é½æ£€ç´¢è„šæœ¬çš„ç›¸ä¼¼åº¦è®¡ç®—
        video_tensor: [batch_size, C, T, H, W]
        è¿”å›: [batch_size, num_texts] ç›¸ä¼¼åº¦logits
        """
        video_tensor = video_tensor.float()
        
        # è·å–è§†é¢‘embedding
        video_inputs = {'video': {'pixel_values': video_tensor}}
        video_embeddings = self.model(video_inputs)['video']  # [batch_size, embed_dim]
        
        # å¯¹é½åŸè„šæœ¬: logit_scale * video @ text.T
        sim_logits = self.logit_scale * video_embeddings @ self.text_embeddings.T
        
        return sim_logits

def load_msrvtt_test_data(csv_file, video_base_path):
    """åŠ è½½MSR-VTTæµ‹è¯•æ•°æ® - å¯¹é½æ£€ç´¢è„šæœ¬"""
    df = pd.read_csv(csv_file)
    
    # æ£€æŸ¥è§†é¢‘æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    valid_indices = []
    for idx, row in df.iterrows():
        video_path = os.path.join(video_base_path, f"{row['video_id']}.mp4")
        if os.path.exists(video_path):
            valid_indices.append(idx)
    
    if len(valid_indices) == 0:
        raise FileNotFoundError(f"åœ¨ {video_base_path} ä¸­æ²¡æœ‰æ‰¾åˆ°ä»»ä½•è§†é¢‘æ–‡ä»¶")
    
    df_valid = df.iloc[valid_indices].reset_index(drop=True)
    
    language_data = df_valid['sentence'].values.tolist()
    video_data = df_valid['video_id'].apply(
        lambda x: os.path.join(video_base_path, f'{x}.mp4')
    ).values.tolist()
    
    logging.info(f"æˆåŠŸåŠ è½½ {len(df_valid)} ä¸ªæœ‰æ•ˆçš„è§†é¢‘-æ–‡æœ¬å¯¹")
    return language_data, video_data, df_valid

def extract_all_features(model, tokenizer, language_data, video_data, modality_transform, batch_size, device):
    """
    æå–æ‰€æœ‰ç‰¹å¾ - å¯¹é½æ£€ç´¢è„šæœ¬çš„ç‰¹å¾æå–æµç¨‹
    """
    logging.info("å¼€å§‹æå–æ‰€æœ‰ç‰¹å¾...")
    model.eval()
    
    # å­˜å‚¨æ‰€æœ‰ç‰¹å¾
    batch_sequence_output_list = []
    batch_visual_output_list = []
    
    with torch.no_grad():
        # 1. æå–æ–‡æœ¬ç‰¹å¾
        logging.info("æå–æ–‡æœ¬ç‰¹å¾...")
        text_batches = list(chunked(language_data, batch_size))
        for batch_texts in tqdm(text_batches, desc="å¤„ç†æ–‡æœ¬æ‰¹æ¬¡"):
            # å¯¹é½æ£€ç´¢è„šæœ¬: model.encode_text()
            text_tokens = tokenizer(batch_texts, max_length=77, padding='max_length', 
                                  truncation=True, return_tensors='pt')
            text_tokens = to_device(text_tokens, device)
            
            # ä½¿ç”¨LanguageBindçš„æ–‡æœ¬ç¼–ç 
            text_inputs = {'language': text_tokens}
            text_embeddings = model(text_inputs)['language']  # [batch_size, embed_dim]
            
            batch_sequence_output_list.append(text_embeddings.cpu())
        
        # 2. æå–è§†é¢‘ç‰¹å¾ 
        logging.info("æå–è§†é¢‘ç‰¹å¾...")
        video_batches = list(chunked(video_data, batch_size))
        for batch_videos in tqdm(video_batches, desc="å¤„ç†è§†é¢‘æ‰¹æ¬¡"):
            # å¯¹é½æ£€ç´¢è„šæœ¬: model.encode_image() / encode_video()
            try:
                video_tensor_dict = modality_transform['video'](batch_videos)
                video_tensor_dict = to_device(video_tensor_dict, device)
                
                video_inputs = {'video': video_tensor_dict}
                video_embeddings = model(video_inputs)['video']  # [batch_size, embed_dim]
                
                batch_visual_output_list.append(video_embeddings.cpu())
                
            except Exception as e:
                logging.warning(f"è·³è¿‡è§†é¢‘æ‰¹æ¬¡: {str(e)}")
                # åˆ›å»ºé›¶å‘é‡ä½œä¸ºå ä½ç¬¦
                dummy_embeddings = torch.zeros(len(batch_videos), 768)  # å‡è®¾768ç»´
                batch_visual_output_list.append(dummy_embeddings)
                continue
    
    # 3. åˆå¹¶æ‰€æœ‰ç‰¹å¾
    all_text_embeddings = torch.cat(batch_sequence_output_list, dim=0)  # [num_texts, embed_dim]
    all_video_embeddings = torch.cat(batch_visual_output_list, dim=0)   # [num_videos, embed_dim]
    
    logging.info(f"æ–‡æœ¬ç‰¹å¾å½¢çŠ¶: {all_text_embeddings.shape}")
    logging.info(f"è§†é¢‘ç‰¹å¾å½¢çŠ¶: {all_video_embeddings.shape}")
    
    return all_text_embeddings.numpy(), all_video_embeddings.numpy()

def compute_full_similarity_matrix(text_embeddings, video_embeddings, logit_scale=100.0):
    """
    è®¡ç®—å®Œæ•´ç›¸ä¼¼åº¦çŸ©é˜µ - å¯¹é½æ£€ç´¢è„šæœ¬
    """
    logging.info("è®¡ç®—å®Œæ•´ç›¸ä¼¼åº¦çŸ©é˜µ...")
    
    # å¯¹é½æ£€ç´¢è„šæœ¬: logit_scale * text @ video.T (æ³¨æ„è¿™é‡Œæ˜¯textåœ¨å‰)
    sim_matrix = logit_scale * text_embeddings @ video_embeddings.T  # [num_texts, num_videos]
    
    logging.info(f"ç›¸ä¼¼åº¦çŸ©é˜µå½¢çŠ¶: {sim_matrix.shape}")
    return sim_matrix

def evaluate_baseline_retrieval(sim_matrix):
    """
    è¯„ä¼°åŸºçº¿æ£€ç´¢æ€§èƒ½ - å¯¹é½æ£€ç´¢è„šæœ¬
    """
    logging.info("è¯„ä¼°åŸºçº¿æ£€ç´¢æ€§èƒ½...")
    
    # Text-to-Videoæ£€ç´¢ (æ¯è¡Œæ˜¯ä¸€ä¸ªæ–‡æœ¬æŸ¥è¯¢)
    tv_metrics = compute_metrics(sim_matrix)
    
    # Video-to-Textæ£€ç´¢ (è½¬ç½®åæ¯è¡Œæ˜¯ä¸€ä¸ªè§†é¢‘æŸ¥è¯¢)
    vt_metrics = compute_metrics(sim_matrix.T)
    
    # å¯¹é½æ£€ç´¢è„šæœ¬çš„æ—¥å¿—æ ¼å¼
    logging.info("MSRVTT Text-to-Video:")
    logging.info(f'\t>>>  R@1: {tv_metrics["R1"]:.1f} - R@5: {tv_metrics["R5"]:.1f} - R@10: {tv_metrics["R10"]:.1f} - Median R: {tv_metrics["MR"]:.1f} - Mean R: {tv_metrics["MeanR"]:.1f}')
    
    logging.info("MSRVTT Video-to-Text:")
    logging.info(f'\t>>>  V2T$R@1: {vt_metrics["R1"]:.1f} - V2T$R@5: {vt_metrics["R5"]:.1f} - V2T$R@10: {vt_metrics["R10"]:.1f} - V2T$Median R: {vt_metrics["MR"]:.1f} - V2T$Mean R: {vt_metrics["MeanR"]:.1f}')
    
    return tv_metrics, vt_metrics

def evaluate_attack_on_subset(attack_method, model, modality_transform, video_data, 
                             text_embeddings, baseline_sim_matrix, args):
    """
    è¯„ä¼°æ”»å‡»æ•ˆæœ - æ­£ç¡®çš„å…¨é›†æ£€ç´¢è¯„ä¼°æ–¹æ³•
    å…³é”®æ€æƒ³ï¼šæ”»å‡»è§†é¢‘ï¼Œä½†åœ¨å…¨éƒ¨1000ä¸ªæ–‡æœ¬ä¸­è¿›è¡Œæ£€ç´¢
    """
    logging.info(f"\nå¼€å§‹è¯„ä¼°æ”»å‡»æ–¹æ³•: {attack_method}")
    
    device = next(model.parameters()).device
    total_samples = len(video_data)
    
    # ç¡®å®šæ”»å‡»æ ·æœ¬èŒƒå›´
    if args.full_dataset_attack or args.n_attack_samples == -1:
        attack_indices = list(range(total_samples))
        logging.info(f"ä½¿ç”¨å…¨æ•°æ®é›†è¿›è¡Œæ”»å‡» ({total_samples} ä¸ªæ ·æœ¬)")
        logging.warning("âš ï¸  å…¨æ•°æ®é›†æ”»å‡»å¯èƒ½éœ€è¦æ•°å°æ—¶æ—¶é—´")
    else:
        attack_indices = random.sample(range(total_samples), 
                                     min(args.n_attack_samples, total_samples))
        logging.info(f"ä½¿ç”¨å­é›†è¿›è¡Œæ”»å‡» ({len(attack_indices)} ä¸ªæ ·æœ¬)")
    
    # ä¸ºæ”»å‡»åˆ›å»ºåŒ…è£…æ¨¡å‹ - æ³¨æ„è¿™é‡Œä½¿ç”¨å…¨éƒ¨æ–‡æœ¬embeddings
    text_embeddings_tensor = torch.tensor(text_embeddings, dtype=torch.float32).to(device)
    wrapped_model = LanguageBindAttackWrapper(model, text_embeddings_tensor, args)
    
    # å­˜å‚¨æ‰€æœ‰æ”»å‡»ç»“æœç”¨äºæœ€ç»ˆçš„å…¨é›†æ£€ç´¢è¯„ä¼°
    all_original_video_embeddings = []
    all_attacked_video_embeddings = []
    all_attack_labels = []  # å¯¹åº”çš„çœŸå®æ–‡æœ¬ç´¢å¼•
    
    total_attack_time = 0
    total_valid_samples = 0
    
    # æŒ‰attack_batch_sizeåˆ†æ‰¹å¤„ç†
    batch_size = args.attack_batch_size
    num_batches = (len(attack_indices) + batch_size - 1) // batch_size
    
    logging.info(f"å°†åˆ† {num_batches} ä¸ªæ‰¹æ¬¡è¿›è¡Œæ”»å‡»ï¼Œæ¯æ‰¹æœ€å¤š {batch_size} ä¸ªæ ·æœ¬")
    logging.info(f"æ¯ä¸ªæ”»å‡»è§†é¢‘å°†åœ¨å…¨éƒ¨ {len(text_embeddings)} ä¸ªæ–‡æœ¬ä¸­è¿›è¡Œæ£€ç´¢")
    
    for batch_idx in tqdm(range(num_batches), desc=f"æ”»å‡»æ‰¹æ¬¡ {attack_method}"):
        start_idx = batch_idx * batch_size
        end_idx = min(start_idx + batch_size, len(attack_indices))
        batch_indices = attack_indices[start_idx:end_idx]
        
        # å‡†å¤‡å½“å‰æ‰¹æ¬¡çš„æ•°æ®
        batch_videos = []
        batch_labels = []
        
        for attack_idx in batch_indices:
            try:
                video_path = video_data[attack_idx]
                if not os.path.exists(video_path):
                    continue
                    
                # é¢„å¤„ç†è§†é¢‘
                video_tensor_dict = modality_transform['video']([video_path])
                video_tensor_dict = to_device(video_tensor_dict, device)
                video_tensor = video_tensor_dict['pixel_values'].float()
                
                batch_videos.append(video_tensor.squeeze(0))
                batch_labels.append(attack_idx)  # çœŸå®æ ‡ç­¾æ˜¯å¯¹åº”çš„æ–‡æœ¬ç´¢å¼•
                
            except Exception as e:
                if args.verbose and batch_idx < 5:  # åªåœ¨å‰å‡ ä¸ªæ‰¹æ¬¡è¾“å‡ºé”™è¯¯
                    logging.warning(f"è·³è¿‡æ ·æœ¬ {attack_idx}: {str(e)}")
                continue
        
        if len(batch_videos) == 0:
            continue
        
        # è½¬æ¢ä¸ºtensor
        x_batch = torch.stack(batch_videos).to(device)
        y_batch = torch.tensor(batch_labels, dtype=torch.long).to(device)
        
        # è·å–åŸå§‹è§†é¢‘embeddings (ç”¨äºæœ€ç»ˆæ£€ç´¢è¯„ä¼°)
        with torch.no_grad():
            original_video_inputs = {'video': {'pixel_values': x_batch}}
            original_video_embeddings = model(original_video_inputs)['video']  # [batch_size, embed_dim]
        
        # è¿è¡Œæ”»å‡»
        adversary = AutoAttack(
            wrapped_model, 
            norm=args.norm.replace('l', 'L'),
            eps=args.eps,
            version='custom',
            attacks_to_run=[attack_method],
            alpha=args.alpha,
            verbose=False
        )
        
        start_time = time.time()
        x_adv, y_adv = adversary.run_standard_evaluation(
            x_batch, y_batch, bs=len(x_batch), return_labels=True
        )
        batch_attack_time = time.time() - start_time
        
        # è·å–æ”»å‡»åçš„è§†é¢‘embeddings
        with torch.no_grad():
            adv_video_inputs = {'video': {'pixel_values': x_adv}}
            adv_video_embeddings = model(adv_video_inputs)['video']  # [batch_size, embed_dim]
        
        # ä¿å­˜embeddingsç”¨äºæœ€ç»ˆçš„å…¨é›†æ£€ç´¢è¯„ä¼°
        all_original_video_embeddings.append(original_video_embeddings.cpu().numpy())
        all_attacked_video_embeddings.append(adv_video_embeddings.cpu().numpy())
        all_attack_labels.extend(batch_labels)
        
        total_attack_time += batch_attack_time
        total_valid_samples += len(batch_labels)
        
        # æ¸…ç†å½“å‰æ‰¹æ¬¡çš„å†…å­˜
        del x_batch, y_batch, x_adv, y_adv, original_video_embeddings, adv_video_embeddings, batch_videos
        torch.cuda.empty_cache()
        
        # è¾“å‡ºè¿›åº¦ä¿¡æ¯
        if (batch_idx + 1) % 10 == 0 or (batch_idx + 1) == num_batches:
            logging.info(f"  å®Œæˆ: {batch_idx + 1}/{num_batches} æ‰¹æ¬¡, "
                        f"ç´¯è®¡æ ·æœ¬: {total_valid_samples}, "
                        f"ç´¯è®¡è€—æ—¶: {total_attack_time:.1f}s")
    
    if total_valid_samples == 0:
        logging.error(f"{attack_method}: æ²¡æœ‰æœ‰æ•ˆçš„æ”»å‡»æ ·æœ¬")
        return None
    
    # ========== å…³é”®ï¼šåœ¨å…¨é›†ä¸Šè¿›è¡Œæ£€ç´¢è¯„ä¼° ==========
    logging.info(f"å¼€å§‹åœ¨å…¨é›†ä¸Šè¯„ä¼° {total_valid_samples} ä¸ªæ”»å‡»æ ·æœ¬çš„æ£€ç´¢æ€§èƒ½...")
    
    # åˆå¹¶æ‰€æœ‰æ”»å‡»æ ·æœ¬çš„embeddings
    all_original_embeddings = np.concatenate(all_original_video_embeddings, axis=0)  # [total_valid_samples, embed_dim]
    all_attacked_embeddings = np.concatenate(all_attacked_video_embeddings, axis=0)   # [total_valid_samples, embed_dim]
    
    logging.info(f"åŸå§‹è§†é¢‘embeddingså½¢çŠ¶: {all_original_embeddings.shape}")
    logging.info(f"æ”»å‡»åè§†é¢‘embeddingså½¢çŠ¶: {all_attacked_embeddings.shape}")
    logging.info(f"æ–‡æœ¬embeddingså½¢çŠ¶: {text_embeddings.shape}")
    
    # è®¡ç®—åœ¨å…¨é›†ä¸Šçš„ç›¸ä¼¼åº¦çŸ©é˜µ
    # æ¯ä¸ªæ”»å‡»çš„è§†é¢‘ä¸å…¨éƒ¨1000ä¸ªæ–‡æœ¬çš„ç›¸ä¼¼åº¦
    original_sim_matrix = 100.0 * all_original_embeddings @ text_embeddings.T  # [n_attack, 1000]
    attacked_sim_matrix = 100.0 * all_attacked_embeddings @ text_embeddings.T   # [n_attack, 1000]
    
    logging.info(f"åŸå§‹ç›¸ä¼¼åº¦çŸ©é˜µå½¢çŠ¶: {original_sim_matrix.shape}")
    logging.info(f"æ”»å‡»åç›¸ä¼¼åº¦çŸ©é˜µå½¢çŠ¶: {attacked_sim_matrix.shape}")
    
    # è®¡ç®—æ¯ä¸ªæ”»å‡»æ ·æœ¬çš„æ£€ç´¢æ€§èƒ½
    original_ranks = []
    attacked_ranks = []
    
    for i, true_label in enumerate(all_attack_labels):
        # åŸå§‹è§†é¢‘çš„æ£€ç´¢æ’å
        original_similarities = original_sim_matrix[i, :]  # ä¸æ‰€æœ‰1000ä¸ªæ–‡æœ¬çš„ç›¸ä¼¼åº¦
        original_sorted_indices = np.argsort(-original_similarities)  # æŒ‰ç›¸ä¼¼åº¦é™åºæ’åº
        original_rank = np.where(original_sorted_indices == true_label)[0][0]  # æ‰¾åˆ°çœŸå®æ ‡ç­¾çš„æ’å
        original_ranks.append(original_rank)
        
        # æ”»å‡»åè§†é¢‘çš„æ£€ç´¢æ’å
        attacked_similarities = attacked_sim_matrix[i, :]
        attacked_sorted_indices = np.argsort(-attacked_similarities)
        attacked_rank = np.where(attacked_sorted_indices == true_label)[0][0]
        attacked_ranks.append(attacked_rank)
    
    original_ranks = np.array(original_ranks)
    attacked_ranks = np.array(attacked_ranks)
    
    # è®¡ç®—æ£€ç´¢æŒ‡æ ‡
    def compute_retrieval_metrics(ranks):
        metrics = {}
        metrics['R1'] = float(np.sum(ranks == 0)) * 100 / len(ranks)
        metrics['R5'] = float(np.sum(ranks < 5)) * 100 / len(ranks)
        metrics['R10'] = float(np.sum(ranks < 10)) * 100 / len(ranks)
        metrics['MR'] = np.median(ranks) + 1
        metrics['MeanR'] = np.mean(ranks) + 1
        return metrics
    
    original_metrics = compute_retrieval_metrics(original_ranks)
    attacked_metrics = compute_retrieval_metrics(attacked_ranks)
    
    # è®¡ç®—æ”»å‡»æˆåŠŸç‡ (åŸºäºæ’åå˜åŒ–)
    rank_degradation = np.mean(attacked_ranks - original_ranks)  # å¹³å‡æ’åä¸‹é™
    successful_attacks = np.sum(attacked_ranks > original_ranks)  # æ’åå˜å·®çš„æ ·æœ¬æ•°
    attack_success_rate = successful_attacks / len(original_ranks)
    
    # è®¡ç®—å‡†ç¡®ç‡æŒ‡æ ‡ (R@1)
    original_accuracy = original_metrics['R1']
    robust_accuracy = attacked_metrics['R1'] 
    accuracy_drop = original_accuracy - robust_accuracy
    
    # å¯¹æ¯”åŸºçº¿æ€§èƒ½ (ä»å®Œæ•´baselineä¸­æå–å¯¹åº”æ ·æœ¬çš„æ€§èƒ½)
    baseline_ranks = []
    for true_label in all_attack_labels:
        baseline_similarities = baseline_sim_matrix[true_label, :]  # ä»åŸºçº¿ç›¸ä¼¼åº¦çŸ©é˜µä¸­æå–
        baseline_sorted_indices = np.argsort(-baseline_similarities)
        baseline_rank = np.where(baseline_sorted_indices == true_label)[0][0]
        baseline_ranks.append(baseline_rank)
    
    baseline_ranks = np.array(baseline_ranks)
    baseline_metrics = compute_retrieval_metrics(baseline_ranks)
    
    # æ•´ç†ç»“æœ
    results = {
        'attack_method': attack_method,
        'dataset_scope': 'å…¨æ•°æ®é›†' if (args.full_dataset_attack or args.n_attack_samples == -1) else 'å­é›†',
        'total_samples': total_valid_samples,
        'attack_time': total_attack_time,
        'avg_time_per_sample': total_attack_time / total_valid_samples,
        
        # åŸºçº¿æ€§èƒ½ (è¿™äº›æ ·æœ¬åœ¨åŸºçº¿è¯„ä¼°ä¸­çš„è¡¨ç°)
        'baseline_r1': baseline_metrics['R1'],
        'baseline_r5': baseline_metrics['R5'],
        'baseline_r10': baseline_metrics['R10'],
        
        # æ”»å‡»å‰æ€§èƒ½ (åº”è¯¥ä¸åŸºçº¿æ¥è¿‘)
        'original_r1': original_metrics['R1'],
        'original_r5': original_metrics['R5'],
        'original_r10': original_metrics['R10'],
        'original_mean_rank': original_metrics['MeanR'],
        
        # æ”»å‡»åæ€§èƒ½
        'attacked_r1': attacked_metrics['R1'],
        'attacked_r5': attacked_metrics['R5'],
        'attacked_r10': attacked_metrics['R10'],
        'attacked_mean_rank': attacked_metrics['MeanR'],
        
        # æ”»å‡»æ•ˆæœæŒ‡æ ‡
        'r1_drop': original_metrics['R1'] - attacked_metrics['R1'],
        'r5_drop': original_metrics['R5'] - attacked_metrics['R5'],
        'r10_drop': original_metrics['R10'] - attacked_metrics['R10'],
        'mean_rank_increase': attacked_metrics['MeanR'] - original_metrics['MeanR'],
        'attack_success_rate': attack_success_rate,
        'mean_rank_degradation': rank_degradation
    }
    
    # è¾“å‡ºè¯¦ç»†ç»“æœ
    logging.info(f"\n{attack_method} å…¨é›†æ£€ç´¢è¯„ä¼°ç»“æœ:")
    logging.info(f"  æ”»å‡»èŒƒå›´: {results['dataset_scope']} ({total_valid_samples} ä¸ªæ ·æœ¬)")
    logging.info(f"  æ€»æ”»å‡»è€—æ—¶: {total_attack_time:.1f}ç§’")
    logging.info(f"  å¹³å‡æ¯æ ·æœ¬: {total_attack_time / total_valid_samples:.2f}ç§’")
    logging.info(f"")
    logging.info(f"  åŸºçº¿æ£€ç´¢æ€§èƒ½:")
    logging.info(f"    R@1: {baseline_metrics['R1']:.2f}% | R@5: {baseline_metrics['R5']:.2f}% | R@10: {baseline_metrics['R10']:.2f}%")
    logging.info(f"")  
    logging.info(f"  æ”»å‡»å‰æ£€ç´¢æ€§èƒ½:")
    logging.info(f"    R@1: {original_metrics['R1']:.2f}% | R@5: {original_metrics['R5']:.2f}% | R@10: {original_metrics['R10']:.2f}%")
    logging.info(f"")
    logging.info(f"  æ”»å‡»åæ£€ç´¢æ€§èƒ½:")
    logging.info(f"    R@1: {attacked_metrics['R1']:.2f}% | R@5: {attacked_metrics['R5']:.2f}% | R@10: {attacked_metrics['R10']:.2f}%")
    logging.info(f"")
    logging.info(f"  æ”»å‡»æ•ˆæœ:")
    logging.info(f"    R@1ä¸‹é™: {original_metrics['R1'] - attacked_metrics['R1']:.2f}%")
    logging.info(f"    R@5ä¸‹é™: {original_metrics['R5'] - attacked_metrics['R5']:.2f}%")
    logging.info(f"    R@10ä¸‹é™: {original_metrics['R10'] - attacked_metrics['R10']:.2f}%")
    logging.info(f"    å¹³å‡æ’åæ¶åŒ–: {rank_degradation:.2f}")
    logging.info(f"    æ”»å‡»æˆåŠŸç‡: {attack_success_rate:.3f}")
    
    return results

def main():
    args = parser.parse_args()
    
    # è®¾ç½®éšæœºç§å­
    torch.manual_seed(42)
    np.random.seed(42)
    random.seed(42)
    
    # è½¬æ¢å‚æ•°èŒƒå›´ (å¯¹é½RobustBench)
    args.eps = args.eps / 255
    args.alpha = args.alpha / 255
    
    logging.info(f"å®éªŒé…ç½®:\n{'-' * 50}")
    for arg, value in vars(args).items():
        logging.info(f"{arg}: {value}")
    logging.info(f"{'-' * 50}")
    
    # è®¾å¤‡é…ç½®
    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
    logging.info(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    # ç¡®å®šæ”»å‡»æ–¹æ³•
    if args.attacks_to_run is not None:
        attacks_to_run = args.attacks_to_run
    elif args.blackbox_only:
        attacks_to_run = ['square']
    else:
        # attacks_to_run = ['apgd-ce', 'apgd-dlr', 'fab', 'apgd-t', 'fab-t']
        attacks_to_run = ['apgd-t']
    logging.info(f'è®¡åˆ’è¿è¡Œçš„æ”»å‡»æ–¹æ³•: {attacks_to_run}')
    
    # åŠ è½½LanguageBindæ¨¡å‹
    logging.info("åŠ è½½LanguageBindæ¨¡å‹...")
    clip_type = {'video': args.clip_type}
    model = LanguageBind(clip_type=clip_type, cache_dir=args.cache_dir).to(device)
    model.eval()
    
    tokenizer = LanguageBindImageTokenizer.from_pretrained(
        'lb203/LanguageBind_Image', 
        cache_dir=os.path.join(args.cache_dir, 'tokenizer_cache_dir')
    )
    
    modality_transform = {c: transform_dict[c](model.modality_config[c]) for c in clip_type.keys()}
    
    # åŠ è½½æµ‹è¯•æ•°æ®
    language_data, video_data, df_valid = load_msrvtt_test_data(args.csv_file, args.video_base_path)
    
    # ========== ç¬¬ä¸€é˜¶æ®µ: æå–æ‰€æœ‰ç‰¹å¾å¹¶è®¡ç®—åŸºçº¿æ€§èƒ½ ==========
    text_embeddings, video_embeddings = extract_all_features(
        model, tokenizer, language_data, video_data, 
        modality_transform, args.batch_size, device
    )
    
    # è®¡ç®—å®Œæ•´ç›¸ä¼¼åº¦çŸ©é˜µ
    sim_matrix = compute_full_similarity_matrix(text_embeddings, video_embeddings)
    
    # è¯„ä¼°åŸºçº¿æ£€ç´¢æ€§èƒ½
    baseline_tv_metrics, baseline_vt_metrics = evaluate_baseline_retrieval(sim_matrix)
    
    # ========== ç¬¬äºŒé˜¶æ®µ: å¯¹æ¯ç§æ”»å‡»æ–¹æ³•è¿›è¡Œè¯„ä¼° ==========
    all_attack_results = []
    
    for attack_method in attacks_to_run:
        try:
            result = evaluate_attack_on_subset(
                attack_method, model, modality_transform, video_data,
                text_embeddings, sim_matrix, args
            )
            if result:
                all_attack_results.append(result)
        except Exception as e:
            logging.error(f"æ”»å‡»æ–¹æ³• {attack_method} æ‰§è¡Œå¤±è´¥: {str(e)}")
            continue
    
    # ========== ç¬¬ä¸‰é˜¶æ®µ: ç»“æœæ±‡æ€»å’Œåˆ†æ ==========
    logging.info("\n" + "="*100)
    logging.info("æ”»å‡»è¯„ä¼°ç»“æœæ±‡æ€»:")
    logging.info("="*100)
    
    if all_attack_results:
        # æŒ‰R@1ä¸‹é™æ’åº (ä¸»è¦æ”»å‡»æ•ˆæœæŒ‡æ ‡)
        all_attack_results.sort(key=lambda x: x.get('r1_drop', 0), reverse=True)
        
        logging.info(f"{'æ”»å‡»æ–¹æ³•':<12} {'æ ·æœ¬æ•°':<6} {'åŸºçº¿R@1':<8} {'æ”»å‡»å‰R@1':<10} {'æ”»å‡»åR@1':<10} {'R@1ä¸‹é™':<8} {'R@5ä¸‹é™':<8} {'æˆåŠŸç‡':<8}")
        logging.info("-"*100)
        
        for result in all_attack_results:
            logging.info(f"{result['attack_method']:<12} "
                        f"{result['total_samples']:<6} "
                        f"{result.get('baseline_r1', 0):.1f}%     "
                        f"{result.get('original_r1', 0):.1f}%       "
                        f"{result.get('attacked_r1', 0):.1f}%       "
                        f"{result.get('r1_drop', 0):.1f}%    "
                        f"{result.get('r5_drop', 0):.1f}%    "
                        f"{result.get('attack_success_rate', 0):.3f}")
        
        # æ‰¾å‡ºæœ€æœ‰æ•ˆçš„æ”»å‡»æ–¹æ³•
        best_method = all_attack_results[0]
        logging.info(f"\nğŸ† æœ€æœ‰æ•ˆçš„æ”»å‡»æ–¹æ³•: {best_method['attack_method']}")
        logging.info(f"   R@1ä¸‹é™: {best_method.get('r1_drop', 0):.2f}%")
        logging.info(f"   R@5ä¸‹é™: {best_method.get('r5_drop', 0):.2f}%")
        logging.info(f"   æ”»å‡»æˆåŠŸç‡: {best_method.get('attack_success_rate', 0):.3f}")
        logging.info(f"   å¹³å‡æ’åæ¶åŒ–: {best_method.get('mean_rank_degradation', 0):.1f}")
    
    # ========== ä¿å­˜ç»“æœ ==========
    if args.save_results:
        results_data = {
            'experiment_config': vars(args),
            'baseline_performance': {
                'text_to_video': baseline_tv_metrics,
                'video_to_text': baseline_vt_metrics
            },
            'attack_results': all_attack_results,
            'summary': {
                'best_attack': best_method['attack_method'] if all_attack_results else None,
                'max_r1_drop': best_method.get('r1_drop', 0) if all_attack_results else 0,
                'max_r5_drop': best_method.get('r5_drop', 0) if all_attack_results else 0,
                'max_success_rate': best_method.get('attack_success_rate', 0) if all_attack_results else 0
            } if all_attack_results else {}
        }
        
        timestamp = time.strftime("%Y-%m-%d_%H-%M-%S")
        results_file = f'{args.experiment_name}_{args.norm}_eps{int(args.eps*255)}_{timestamp}.json'
        
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(results_data, f, indent=2, ensure_ascii=False)
        logging.info(f"\nè¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: {results_file}")

if __name__ == "__main__":
    main()